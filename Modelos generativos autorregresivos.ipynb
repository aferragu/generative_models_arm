{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca84d73f-9521-4b85-944b-8daa6f4d2617",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Modelos Generativos Autorregresivos\n",
    "\n",
    "\n",
    "## Andrés Ferragut\n",
    "\n",
    "\n",
    "### Basado en el material de:\n",
    "\n",
    "  * \"[Probabilistic Machine Learning: Advanced Topics](https://probml.github.io/pml-book/book2.html)\", Kevin P. Murphy, MIT Press, 2023.\n",
    "  * \"[Deep Generative Modeling](https://link.springer.com/book/10.1007/978-3-030-93158-2)\", Jakub M. Tomczak, Springer, 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a56519b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pytorch_model_summary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22939a5-9e09-4f7c-bb0c-3b155e057fa4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Modelos generativos\n",
    "\n",
    "**Idea:** Ajustar una densidad $p(\\mathbf{x})$ que permita generar de manera eficiente muestras de la variable $\\mathbf{x}$.\n",
    "\n",
    "**Problema:** Típicamente $\\mathbf{x}$ vive en un espacio complicado. Ejemplo: imágenes ByN, $\\mathbf{x}\\in\\{0,\\ldots,255\\}^T$ con $T$ grande (píxeles). No todas los $\\mathbf{x}$ son igualmente relevantes.\n",
    "\n",
    "### Sabores:\n",
    "\n",
    "  * **No condicional:** Ajusto $p_\\theta(\\mathbf{x})$, genero nuevas muestras en el espacio completo.\n",
    "  * **Condicional:** Ajusto $p_\\theta(\\mathbf{x}\\mid \\mathbf{c})$, siendo $\\mathbf{c}$ un conjunto de *prompts* que dirigen el sampling hacia el tipo de salida que deseo obtener."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c4c46a-ad7c-4ded-a283-41788cbc3736",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Modelos generativos profundos (Deep generative models)\n",
    "\n",
    "* Buscan aplicar redes neuronales profundas para ajustar una densidad condicional $p(\\mathbf{x}\\mid \\mathbf{z})$ desde un conjunto (más pequeño) de variables *latentes* $\\mathbf{z}$.\n",
    "\n",
    "* Combinado con una distribución \"a priori\" $p(\\mathbf{z})$ (postulada), generamos muestras de $p(\\mathbf{x}) = p(\\mathbf{x}\\mid \\mathbf{z})p(\\mathbf{z})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d386be36-d49a-464e-bb92-7c0516dcdacd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Tipos de DGM\n",
    "\n",
    "![tipos](dgm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfe4d0e-08de-4b6f-908b-e22ee14359d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Modelos autorregresivos (ARM)\n",
    "\n",
    "La idea básica es descomponer $p(\\mathbf{x})$ como:\n",
    "\n",
    "$$p(\\mathbf{x}) = p(x_1)p(x_2\\mid x_1)p(x_3\\mid x_1,x_2) \\ldots = \\prod_{i=1}^T p(x_t\\mid x_{1:t-1})$$\n",
    "\n",
    "siendo $x_t$ la coordenada $t$ de $\\mathbf{x}$, $x_{1:t-1}$ las primeras $t-1$ coordenadas, y $p(x_1\\mid x_{1:0})\\equiv p(x_1)$ la marginal de la primera coordenada.\n",
    "\n",
    "\n",
    "**Problema:** si bien la descomposición es válida, $p(x_t\\mid x_{1:t-1})$ es cada vez más compleja si dejamos que dependa de toda la historia pasada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3444b2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Objetivo\n",
    "\n",
    "En general el objetivo es maximizar la verosimilitud logarítmica de lo anterior, que corresponde a:\n",
    "\n",
    "$$ \\log p(\\mathbf{x}) = \\sum_{i=1}^T \\log\\left(p(x_t\\mid x_{1:t-1})\\right)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384eb1b7-7729-4ab6-ac55-e0aba3475851",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Simplificaciones:\n",
    "\n",
    "* Modelo markoviano: suponer $p(x_t\\mid x_{1:t-1}) = p(x_t\\mid x_{t-1})$ (o AR(1)).\n",
    "* AR($k$):   suponer $p(x_t\\mid x_{1:t-1}) = p(x_t\\mid x_{t-k:t-1})$\n",
    "* HMM: Usar un estado latente, tal que $z_t$ es una cadena de Markov, y $p(x_t\\mid x_{1:t-1})= p(x_t\\mid z_t)$. Esto produce un modelo markoviano escondido.\n",
    "\n",
    "* RNN: Usar un estado latente $z_t$ y modelar:\n",
    "    $$p(x_t\\mid  x_{1:t-1}) = p(x_t\\mid z_t)f(z_t\\mid x_{1:t-1})$$\n",
    "\n",
    "Es decir, comprimimos la historia en un estado latente $z_t$ que es función (no lineal) determinística de la historia. Esto produce lo que se denomina una *red neuronal recurrente*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e02904d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Deep autoregresive models\n",
    "\n",
    "**Idea:**\n",
    "\n",
    " * Mantenerse en el modelo ARM de la ecuación anterior...\n",
    " * Pero plantear una forma funcional (por ejemplo red neuronal) para las condicionales:\n",
    " \n",
    " $$ p(x_t\\mid x_{1:t-1}) $$\n",
    " \n",
    "En lugar de hacer hipótesis de independencia condicional, o comprimir el pasado en un estado latente $z$ (estadístico suficiente del pasado), aprender un mapa compacto del pasado hacia el futuro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c832654",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deep autoregresive models\n",
    "\n",
    "### Ventajas\n",
    "\n",
    " * Se puede calcular (y optimizar en los parámetros) la verosimilitud exacta $p(\\mathbf{x})$.\n",
    " * Se puede generar datos nuevos de manera recursiva...\n",
    " \n",
    "### Desventajas\n",
    "\n",
    " * Al ser recursivos, la generación puede ser lenta.\n",
    " * Al no haber una representación compacta, es difícil *extraer* características como hacemos con las variables latentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e1c5e3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejemplo: Neural autoregressive density estimators (NADE)\n",
    "\n",
    "Propuestos por Larochelle & Murray [[LM11]](https://proceedings.mlr.press/v15/larochelle11a/larochelle11a.pdf).\n",
    "\n",
    "**Idea:** Si mis observaciones $x_t\\in\\{0,1\\}$ entonces modelo:\n",
    "\n",
    "$$\\begin{cases}\\theta_t = P(x_t=1\\mid x_{1:t-1}) = \\sigma(b_t + W^h_t h_t), \\\\ h_t = \\sigma(\\mathbf{c} + W^\\theta_t \\theta_{1:t-1}).\\end{cases}$$\n",
    "\n",
    "Similar a una red neuronal recurrente. $h_t$ actúa como una variable de estado oculta. Las matrices $W^h_t$ y $W^\\theta_t$ dependen del tiempo. Ojo que $W^\\theta$ crece en tamaño con $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af392140",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejemplo: Real valued neural autoregressive density estimator (RNADE)\n",
    "\n",
    "Propuestos por Uria, Murray & Larochelle [ULM13](https://arxiv.org/abs/1306.0186):\n",
    "\n",
    "**Idea:** Más en general, si $x_t$ es a valores reales, entonces modelo $x_t$ como una mezcla de gaussianas:\n",
    "\n",
    "$$p(x_t\\mid x_{1:t-1}) = \\sum_{k=1}^K \\pi_{t,k} \\mathcal{N}(x_t\\mid \\mu_{t,k}, \\sigma^2_{t,k})$$\n",
    "\n",
    "Con los parámetros de las gaussianas:\n",
    "\n",
    "$$(\\pi_t,\\mu_t,\\sigma_t) = f_t(x_{1:t-1}\\mid \\theta_t)$$\n",
    "\n",
    "donde $f$ es una red neuronal (en principio arbitraria, pero...)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a33574",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejemplo: RNADE, detalles\n",
    "\n",
    "Más concretamente [ULM13](https://arxiv.org/abs/1306.0186) propone la siguiente estructura:\n",
    "\n",
    "Activaciones:\n",
    "$$a_1 = c, \\quad a_{t+1} = a_t + x_t^T W_t$$\n",
    "    \n",
    "    \n",
    "Variables latentes:\n",
    "\n",
    "$$h_t = \\mathrm{RelU}(\\rho_t a_t)$$\n",
    "    \n",
    "Parámetros de la mezcla gaussiana:\n",
    "\n",
    "* *Mixing fractions:* $$\\pi_t = \\mathrm{softmax}(V^\\pi_t h_t + b^\\pi_t).$$\n",
    "\n",
    "* *Means:* $$\\mu_t = V^{\\mu}_t h_t + b^{\\mu}_t.$$\n",
    "\n",
    "* *Standard deviations:* $$\\sigma_t = \\exp(V^{\\sigma}_t h_t + b^{\\sigma}_t).$$\n",
    "\n",
    "**Parámetros a entrenar:** $c$, $W_t$, $\\rho_t$, $V^\\pi_t$, $V^\\mu_t$, $V^{\\sigma}_t$, $b^\\pi_t$, $b^{\\mu}_t$, $V^\\sigma_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14bd946",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Limited memory (Tomczak 2.2.1)\n",
    "\n",
    "Esto corresponde a un modelo $AR(k)$ no lineal. A modo de ejemplo se presenta el siguiente modelo:\n",
    "\n",
    "$$p(\\mathbf{x}) = p(x_1)p(x_2\\mid x_1) \\prod_{t=3}^T p(x_t\\mid x_{t-1},x_{t-2}).$$\n",
    "\n",
    "Luego se usa una red neuronal simple para modelar $p(x_t\\mid x_{t-1},x_{t-2})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72b6ef7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ejemplo:\n",
    "\n",
    "Si $x\\in \\mathcal{X} = \\{0,\\ldots,255\\}$ entonces $p(x_t\\mid x_{t-1},x_{t-2})$ es una distribución de probabilidad $\\theta_t$ en $\\mathcal{X}$. Podemos hacer un modelo de la forma:\n",
    "\n",
    "$$[x_{t-1},x_{t-2})] \\to \\mathrm{Dense}(2,M) \\to \\mathrm{ReLU} \\to \\mathrm{Dense}(M,256) \\to \\mathrm{softmax} \\to \\theta_d.$$\n",
    "\n",
    "O bien en ecuaciones:\n",
    "\n",
    "$$\\begin{cases} h_t = \\mathrm{ReLU}\\left(W \\begin{bmatrix}x_{t-1}\\\\x_{t-2} \\end{bmatrix}\\right)\\\\ \n",
    "\\theta_t = \\mathrm{softmax}( V h_t) \\end{cases}$$\n",
    "\n",
    "Con $W$ de $M\\times 2$ y $V$ de $256\\times M$, siendo $M$ el número de variables latentes.\n",
    "\n",
    "A entrenar: $W, V$. $M$ es un hiperparámetro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c42b9f2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ejemplo: gráficamente\n",
    "\n",
    "![AR2](neural_ar2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24749b89",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problemas\n",
    "\n",
    "* Estamos usando un único modelo homogéneo (dado por $W$ y $V$) para codificar todas las dependendcias.\n",
    "* La ventaja es que requiere pocos parámetros, pero asume cierta estacionariedad de los datos.\n",
    "* No es claro cómo elegir la memoria $M$ del modelo.\n",
    "\n",
    "\n",
    "**Pregunta:** ¿sería posible cambiar $W$ y $V$ por $W_t$, $V_t$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50bba18",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Long range memory y RNN (Tomczak 2.2.2)\n",
    "\n",
    "La segunda idea es utilizar una red neuronal recurrente, es decir modelar:\n",
    "\n",
    "$$p(x_t\\mid x_{1:t-1}) = p(x_t \\mid \\mathrm{RNN}(x_{t-1},h_{t-1}))$$\n",
    "\n",
    "Siendo $\\mathrm{RNN}(x_{t-1},h_{t-1})$ una red neuronal recurrente, y $h_t$ un *hidden context* o variable de estado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c23ea3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RNN: descripción gráfica.\n",
    "\n",
    "![RNN](rnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477b43f2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RNN: ecuaciones\n",
    "\n",
    "Las ecuaciones para el mismo modelo que antes serían:\n",
    "\n",
    "$$\\begin{cases}\n",
    "h_t  = \\sigma\\left(W h_{t-1} + V x_{t-1} + b \\right) \\\\\n",
    "\\theta_t = \\mathrm{softmax}(h_t)\n",
    "\\end{cases}$$\n",
    "\n",
    "con $\\sigma$ una no linealidad a elegir, y $W$, $V$, $b$ parámetros a entrenar.\n",
    "\n",
    "**Pregunta:** ¿podemos cambiar por $W_t$, $V_t$, $b_t$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008bc2e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problemas: vanishing and exploding gradients\n",
    "\n",
    "* La parametrización es eficiente, pero presenta los mismos problemas que antes (homogeneidad).\n",
    "* Es secuencial por lo que es lenta de generar nuevas secuencias.\n",
    "* Aparecen las potencias de $V$ y $W$ en el gradiente, por lo que sin reescalar, si los valores propios de $W$ y $V$ se alejan de $1$ el gradiente tiende a $0$ o $\\infty$ (vanishing and exploding gradients)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2df6984",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## (Causal) Convolutional Neural Networks.\n",
    "\n",
    "Las redes *convolucionales* surgen como una alternativa para capturar dependencias de largo plazo: útiles en imágenes y análisis de texto.\n",
    "\n",
    "**Definición (en dimensión 1):**\n",
    "\n",
    "$$o_t = \\sigma\\left(\\sum_{k} W_k x_{t-k} + b\\right)$$\n",
    "\n",
    "**Problema:** en principio $W_k$ puede usar valores futuros de $x_t$ para calcular $o_t$, por lo que a los efectos de generar un modelo *generativo recursivo* no nos sirve.\n",
    "\n",
    "**Solución:** usar solo convoluciones causales..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc9602d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejemplo (Tomczak, 2.2.3):\n",
    "\n",
    "En el libro, Tomczak define dos tipos de convoluciones causales:\n",
    "\n",
    " * **Tipo A:** se calcula $o_t$ usando solo valores *anteriores* de $x_t$.\n",
    " * **Tipo B:** se calcula $o_t$ usando valores anteriores y el valor actual de $x_t$.\n",
    " \n",
    "No podemos usar solo tipo B, porque dependería de la muestra actual (a generar), pero podemos hacer *stacking* de capas tipo A y B, comenzando por tipo A.\n",
    "\n",
    "A su vez propone usar diferentes escalas de **dilatación** (dilation) para ir capturando las dependencias de largo plazo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3381f915",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejemplo CNN: representación gráfica.\n",
    "\n",
    "![deep_cnn](deep_cnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667c9ab7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Implementación en PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f059a78a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class CausalConv1d(nn.Module):\n",
    "    \"\"\"\n",
    "    A causal 1D convolution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation, A=False, **kwargs):\n",
    "        super(CausalConv1d, self).__init__()\n",
    "\n",
    "        # attributes:\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dilation = dilation\n",
    "        self.A = A\n",
    "        \n",
    "        self.padding = (kernel_size - 1) * dilation + A * 1\n",
    "\n",
    "        # module:\n",
    "        self.conv1d = torch.nn.Conv1d(in_channels, out_channels,\n",
    "                                      kernel_size, stride=1,\n",
    "                                      padding=0,\n",
    "                                      dilation=dilation,\n",
    "                                      **kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.pad(x, (self.padding, 0))\n",
    "        conv1d_out = self.conv1d(x)\n",
    "        if self.A:\n",
    "            return conv1d_out[:, :, : -1]\n",
    "        else:\n",
    "            return conv1d_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e120719",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejemplo: un datasets de dígitos reducido\n",
    "\n",
    "Para tener un ejemplo sencillo, se propone utilizar un dataset de imágenes de dígitos:\n",
    "\n",
    " * El dataset `digits` de `SciPy` consiste en $\\approx 1500$ imágenes de dígitos.\n",
    " * Cada imagen tiene 17 niveles de gris. Es decir $\\mathcal{X} = \\{0,\\ldots,16\\}$.\n",
    " * Las imágenes son de $8\\times 8$ píxeles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba4ee808",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class Digits(Dataset):\n",
    "    \"\"\"Scikit-Learn Digits dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, mode='train', transforms=None):\n",
    "        digits = load_digits()\n",
    "        if mode == 'train':\n",
    "            self.data = digits.data[:1000].astype(np.float32)\n",
    "        elif mode == 'val':\n",
    "            self.data = digits.data[1000:1350].astype(np.float32)\n",
    "        else:\n",
    "            self.data = digits.data[1350:].astype(np.float32)\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e89ff88",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff108c9a390>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plottable_image = np.reshape(Digits()[0], (8, 8))\n",
    "plt.imshow(plottable_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431315ee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Función objetivo: máxima verosimilitud\n",
    "\n",
    "Si tenemos $\\mathcal{D} = \\{\\mathbf{x}_1,\\ldots,\\mathbf{x}_N\\}$ datos, buscamos maximizar la verosimilitud dada por:\n",
    "\n",
    "$$\\mathcal{L} = \\sum_{n} p(\\mathbf{x}_n) = \\sum_n\\left(\\sum_t \\log p(x_{n,t}\\mid x_{n,[1:t-1]})\\right)$$\n",
    "\n",
    "Para cada imagen $n$ anterior, $p(x_{n,t}\\mid x_{n,[1:t-1]})$ corresponde a nuestra distribución categórica, por lo que:\n",
    "\n",
    "$$p(x_{n,t}\\mid x_{n,[1:t-1]}) = \\log\\left(\\prod_{l=1}^L \\theta_{t,l}^{\\mathbf{1}_{\\{x_t=l\\}}}  \\right) = \\sum_{l=1}^L \\mathbf{1}_{\\{x_t=l\\}}\\log (\\theta_{t,l}).$$\n",
    "\n",
    "Por lo tanto la función objetivo es aditiva:\n",
    "\n",
    "$$\\mathcal{L} = \\sum_{n=1}^N \\sum_{t=1}^{T} \\sum_{l=1}^L \\mathbf{1}_{\\{x_t=l\\}}\\log\\left( \\theta_{t,l}\\right)$$\n",
    "\n",
    "con $\\theta_{t,\\cdot}$ el vector de probabilidades salida del modelo en tiempo $t$.\n",
    "\n",
    "$N=$ cantidad de imágenes, $T=$ cantidad de píxeles, $L=$ niveles por píxel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4693aa35",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementación\n",
    "\n",
    "### Función de costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e56ea24",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "EPS = 1.e-5\n",
    "\n",
    "def log_categorical(x, p, num_classes=256, reduction=None, dim=None):\n",
    "    x_one_hot = F.one_hot(x.long(), num_classes=num_classes)\n",
    "    log_p = x_one_hot * torch.log(torch.clamp(p, EPS, 1. - EPS))\n",
    "    if reduction == 'avg':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90578589",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Modelo Autorregresivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71ed0d9e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class ARM(nn.Module):\n",
    "    def __init__(self, net, D=2, num_vals=256):\n",
    "        super(ARM, self).__init__()\n",
    "\n",
    "        print('ARM by JT.')\n",
    "\n",
    "        self.net = net\n",
    "        self.num_vals = num_vals\n",
    "        self.D = D\n",
    "\n",
    "    def f(self, x):\n",
    "        h = self.net(x.unsqueeze(1))\n",
    "\n",
    "        h = h.permute(0, 2, 1)\n",
    "        p = torch.softmax(h, 2)\n",
    "        return p\n",
    "        \n",
    "    def forward(self, x, reduction='avg'):\n",
    "        if reduction == 'avg':\n",
    "            return -(self.log_prob(x).mean())\n",
    "        elif reduction == 'sum':\n",
    "            return -(self.log_prob(x).sum())\n",
    "        else:\n",
    "            raise ValueError('reduction could be either `avg` or `sum`.')\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        mu_d = self.f(x)\n",
    "        log_p = log_categorical(x, mu_d, num_classes=self.num_vals, reduction='sum', dim=-1).sum(-1)\n",
    "        \n",
    "        return log_p\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        x_new = torch.zeros((batch_size, self.D))\n",
    "\n",
    "        for d in range(self.D):\n",
    "            p = self.f(x_new)\n",
    "            x_new_d = torch.multinomial(p[:, d, :], num_samples=1)\n",
    "            x_new[:, d] = x_new_d[:,0]\n",
    "\n",
    "        return x_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d160e20",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Funciones auxiliares (plotting, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f97a9a7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def evaluation(test_loader, name=None, model_best=None, epoch=None):\n",
    "    # EVALUATION\n",
    "    if model_best is None:\n",
    "        # load best performing model\n",
    "        model_best = torch.load(name + '.model')\n",
    "\n",
    "    model_best.eval()\n",
    "    loss = 0.\n",
    "    N = 0.\n",
    "    for indx_batch, test_batch in enumerate(test_loader):\n",
    "        loss_t = model_best.forward(test_batch, reduction='sum')\n",
    "        loss = loss + loss_t.item()\n",
    "        N = N + test_batch.shape[0]\n",
    "    loss = loss / N\n",
    "\n",
    "    if epoch is None:\n",
    "        print(f'FINAL LOSS: nll={loss}')\n",
    "    else:\n",
    "        print(f'Epoch: {epoch}, val nll={loss}')\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def samples_real(name, test_loader):\n",
    "    # REAL-------\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x = next(iter(test_loader)).detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], (8, 8))\n",
    "        ax.imshow(plottable_image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.savefig(name+'_real_images.pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def samples_generated(name, data_loader, extra_name=''):\n",
    "    x = next(iter(data_loader)).detach().numpy()\n",
    "\n",
    "    # GENERATIONS-------\n",
    "    model_best = torch.load(name + '.model')\n",
    "    model_best.eval()\n",
    "\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x = model_best.sample(num_x * num_y)\n",
    "    x = x.detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], (8, 8))\n",
    "        ax.imshow(plottable_image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.savefig(name + '_generated_images' + extra_name + '.pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_curve(name, nll_val):\n",
    "    plt.plot(np.arange(len(nll_val)), nll_val, linewidth='3')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('nll')\n",
    "    plt.savefig(name + '_nll_val_curve.pdf', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75819c93",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Función de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9c8b2ba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def training(name, max_patience, num_epochs, model, optimizer, training_loader, val_loader):\n",
    "    nll_val = []\n",
    "    best_nll = 1000.\n",
    "    patience = 0\n",
    "\n",
    "    # Main loop\n",
    "    for e in range(num_epochs):\n",
    "        # TRAINING\n",
    "        model.train()\n",
    "        for indx_batch, batch in enumerate(training_loader):\n",
    "            if hasattr(model, 'dequantization'):\n",
    "                if model.dequantization:\n",
    "                    batch = batch + torch.rand(batch.shape)\n",
    "            loss = model.forward(batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        loss_val = evaluation(val_loader, model_best=model, epoch=e)\n",
    "        nll_val.append(loss_val)  # save for plotting\n",
    "\n",
    "        if e == 0:\n",
    "            print('saved!')\n",
    "            torch.save(model, name + '.model')\n",
    "            best_nll = loss_val\n",
    "        else:\n",
    "            if loss_val < best_nll:\n",
    "                print('saved!')\n",
    "                torch.save(model, name + '.model')\n",
    "                best_nll = loss_val\n",
    "                patience = 0\n",
    "\n",
    "                samples_generated(name, val_loader, extra_name=\"_epoch_\" + str(e))\n",
    "            else:\n",
    "                patience = patience + 1\n",
    "\n",
    "        if patience > max_patience:\n",
    "            break\n",
    "\n",
    "    nll_val = np.asarray(nll_val)\n",
    "\n",
    "    return nll_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b5ec8d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acbcdc99",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_data = Digits(mode='train')\n",
    "val_data = Digits(mode='val')\n",
    "test_data = Digits(mode='test')\n",
    "\n",
    "training_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "result_dir = 'results/'\n",
    "if not(os.path.exists(result_dir)):\n",
    "    os.mkdir(result_dir)\n",
    "name = 'arm'\n",
    "\n",
    "D = 64   # input dimension\n",
    "M = 256  # the number of neurons in scale (s) and translation (t) nets\n",
    "\n",
    "lr = 1e-3 # learning rate\n",
    "num_epochs = 1000 # max. number of epochs\n",
    "max_patience = 20 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d32761f4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARM by JT.\n",
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "    CausalConv1d-1        [1, 256, 64]           2,048           2,048\n",
      "       LeakyReLU-2        [1, 256, 64]               0               0\n",
      "    CausalConv1d-3        [1, 256, 64]         459,008         459,008\n",
      "       LeakyReLU-4        [1, 256, 64]               0               0\n",
      "    CausalConv1d-5        [1, 256, 64]         459,008         459,008\n",
      "       LeakyReLU-6        [1, 256, 64]               0               0\n",
      "    CausalConv1d-7         [1, 17, 64]          30,481          30,481\n",
      "=======================================================================\n",
      "Total params: 950,545\n",
      "Trainable params: 950,545\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "likelihood_type = 'categorical'\n",
    "\n",
    "num_vals = 17\n",
    "\n",
    "kernel = 7\n",
    "\n",
    "net = nn.Sequential(\n",
    "    CausalConv1d(in_channels=1, out_channels=M, dilation=1, kernel_size=kernel, A=True, bias=True),\n",
    "    nn.LeakyReLU(),\n",
    "    CausalConv1d(in_channels=M, out_channels=M, dilation=1, kernel_size=kernel, A=False, bias=True),\n",
    "    nn.LeakyReLU(),\n",
    "    CausalConv1d(in_channels=M, out_channels=M, dilation=1, kernel_size=kernel, A=False, bias=True),\n",
    "    nn.LeakyReLU(),\n",
    "    CausalConv1d(in_channels=M, out_channels=num_vals, dilation=1, kernel_size=kernel, A=False, bias=True))\n",
    "\n",
    "model = ARM(net, D=D, num_vals=num_vals)\n",
    "\n",
    "# Print the summary (like in Keras)\n",
    "print(summary(model, torch.zeros(1, 64), show_input=False, show_hierarchical=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7eb90005",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, val nll=118.39597446986608\n",
      "saved!\n",
      "Epoch: 1, val nll=112.00656947544643\n",
      "saved!\n",
      "Epoch: 2, val nll=109.764951171875\n",
      "saved!\n",
      "Epoch: 3, val nll=107.87987583705358\n",
      "saved!\n",
      "Epoch: 4, val nll=106.38682407924107\n",
      "saved!\n",
      "Epoch: 5, val nll=104.36825613839285\n",
      "saved!\n",
      "Epoch: 6, val nll=101.91640625\n",
      "saved!\n",
      "Epoch: 7, val nll=99.85006556919643\n",
      "saved!\n",
      "Epoch: 8, val nll=97.85971400669642\n",
      "saved!\n",
      "Epoch: 9, val nll=96.60917689732143\n",
      "saved!\n",
      "Epoch: 10, val nll=95.40817313058035\n",
      "saved!\n",
      "Epoch: 11, val nll=94.18443498883929\n",
      "saved!\n",
      "Epoch: 12, val nll=93.48036342075893\n",
      "saved!\n",
      "Epoch: 13, val nll=93.16297502790178\n",
      "saved!\n",
      "Epoch: 14, val nll=92.93040736607144\n",
      "saved!\n",
      "Epoch: 15, val nll=92.45133370535714\n",
      "saved!\n",
      "Epoch: 16, val nll=91.87165597098215\n",
      "saved!\n",
      "Epoch: 17, val nll=91.85621512276786\n",
      "saved!\n",
      "Epoch: 18, val nll=91.66849051339285\n",
      "saved!\n",
      "Epoch: 19, val nll=91.54071637834821\n",
      "saved!\n",
      "Epoch: 20, val nll=90.97437779017856\n",
      "saved!\n",
      "Epoch: 21, val nll=90.66400111607143\n",
      "saved!\n",
      "Epoch: 22, val nll=90.58865094866071\n",
      "saved!\n",
      "Epoch: 23, val nll=90.43651576450893\n",
      "saved!\n",
      "Epoch: 24, val nll=90.53500069754465\n",
      "Epoch: 25, val nll=90.417802734375\n",
      "saved!\n",
      "Epoch: 26, val nll=90.13023158482143\n",
      "saved!\n",
      "Epoch: 27, val nll=89.98419503348214\n",
      "saved!\n",
      "Epoch: 28, val nll=89.99045061383929\n",
      "Epoch: 29, val nll=90.07170479910714\n",
      "Epoch: 30, val nll=89.64370256696428\n",
      "saved!\n",
      "Epoch: 31, val nll=90.06055594308036\n",
      "Epoch: 32, val nll=89.79851981026786\n",
      "Epoch: 33, val nll=89.37474609375\n",
      "saved!\n",
      "Epoch: 34, val nll=90.440048828125\n",
      "Epoch: 35, val nll=89.91460588727679\n",
      "Epoch: 36, val nll=89.58793387276786\n",
      "Epoch: 37, val nll=89.53390904017857\n",
      "Epoch: 38, val nll=89.27130789620536\n",
      "saved!\n",
      "Epoch: 39, val nll=89.66564871651785\n",
      "Epoch: 40, val nll=89.61035016741072\n",
      "Epoch: 41, val nll=89.45904017857143\n",
      "Epoch: 42, val nll=89.17876255580357\n",
      "saved!\n",
      "Epoch: 43, val nll=89.23912318638394\n",
      "Epoch: 44, val nll=89.34969517299108\n",
      "Epoch: 45, val nll=89.30157366071428\n",
      "Epoch: 46, val nll=89.17407784598214\n",
      "saved!\n",
      "Epoch: 47, val nll=89.60131556919643\n",
      "Epoch: 48, val nll=89.52052734375\n",
      "Epoch: 49, val nll=89.54559012276786\n",
      "Epoch: 50, val nll=89.565751953125\n",
      "Epoch: 51, val nll=89.62366559709821\n",
      "Epoch: 52, val nll=89.72493233816964\n",
      "Epoch: 53, val nll=89.80575823102679\n",
      "Epoch: 54, val nll=90.10963239397321\n",
      "Epoch: 55, val nll=90.14822684151785\n",
      "Epoch: 56, val nll=89.9597314453125\n",
      "Epoch: 57, val nll=89.84141880580357\n",
      "Epoch: 58, val nll=90.2929638671875\n",
      "Epoch: 59, val nll=90.07108747209821\n",
      "Epoch: 60, val nll=90.274248046875\n",
      "Epoch: 61, val nll=90.41599539620536\n",
      "Epoch: 62, val nll=90.21758510044643\n",
      "Epoch: 63, val nll=90.91881487165179\n",
      "Epoch: 64, val nll=90.301953125\n",
      "Epoch: 65, val nll=90.89300920758929\n",
      "Epoch: 66, val nll=90.55435756138392\n",
      "Epoch: 67, val nll=90.99404506138393\n"
     ]
    }
   ],
   "source": [
    "# OPTIMIZER\n",
    "optimizer = torch.optim.Adamax([p for p in model.parameters() if p.requires_grad == True], lr=lr)\n",
    "\n",
    "# Training procedure\n",
    "nll_val = training(name=result_dir + name, max_patience=max_patience, num_epochs=num_epochs, model=model, optimizer=optimizer,\n",
    "                       training_loader=training_loader, val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3972085",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL LOSS: nll=86.56204995106263\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluation(name=result_dir + name, test_loader=test_loader)\n",
    "f = open(result_dir + name + '_test_loss.txt', \"w\")\n",
    "f.write(str(test_loss))\n",
    "f.close()\n",
    "\n",
    "samples_real(result_dir + name, test_loader)\n",
    "\n",
    "plot_curve(result_dir + name, nll_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2969afce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7969acdb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![loss](results/loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece2a997",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Epoch 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77ad5ac",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![loss](results/epoch1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19369fc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Epoch 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf118a1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![loss](results/epoch20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54320cb7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Epoch 46"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4087f9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![loss](results/epoch46.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791fd7c7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusiones\n",
    "\n",
    "Los modelos autorregresivos permiten generar de manera relativamente sencilla nuevas imágenes. La complejidad radica en elegir adecuadamente la forma de capturar las dependencias de largo plazo.\n",
    "\n",
    "En la literatura se ha tenido cierto éxito con su aplicación utilizando redes convolucionales causales, por ejemplo en:\n",
    "\n",
    " * Wavenet (generación de audio).\n",
    " * PixelCNN (generación de imágenes).\n",
    " \n",
    "**Observaciones:**\n",
    "\n",
    " * Para el caso de imágenes, es necesario aplicar *máscaras* al núcleo de convolución para que el procedimiento quede *causal* y así poder generar nuevas imágenes de manera recursiva.\n",
    "\n",
    " * Sigue siendo un mecanismo lento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd47f213",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Muchas gracias!!!\n",
    "\n",
    "Más datos en:\n",
    "\n",
    " * Mi [página](https://aferragu.github.io), donde dejo estas slides.\n",
    " * El [repo de Tomczak](https://github.com/jmtomczak/intro_dgm), en particular el código de ARM que usamos aquí."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
